# -*- coding: utf-8 -*-
"""438 (Updated).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AhCbrl5Uy-RWgNybGjB_OM7DhYokMx6w

# **Accessing the Dataset**
"""

from google.colab import drive
drive.mount('/content/drive')

'''import zipfile
import os

zip_path = '/content/drive/My Drive/Nisarga/Brain Tumor Benchmark Dataset.zip'
extract_path = '/content/drive/My Drive/Nisarga/Brain_Tumor/'

if not os.path.exists(extract_path):
    os.makedirs(extract_path)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)'''

"""# **Dependencies**"""

import numpy as np
import os
import cv2
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

"""# **Data Loading and Pre-Processing**"""

def load_data(data_dir, img_size):
    data = []
    labels = []
    label_mapping = {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}
    for label in os.listdir(data_dir):
        class_dir = os.path.join(data_dir, label)
        for img in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img)
            image = cv2.imread(img_path)
            image = cv2.resize(image, (img_size, img_size))
            data.append(image)
            labels.append(label_mapping[label])
    return np.array(data), np.array(labels)

train_data_dir = '/content/drive/My Drive/Nisarga/Brain_Tumor/Training'
test_data_dir = '/content/drive/My Drive/Nisarga/Brain_Tumor/Testing'
img_size = 224

X_train, y_train = load_data(train_data_dir, img_size)
X_test, y_test = load_data(test_data_dir, img_size)

"""# **Normalizing the Pixel Values**"""

X_train = X_train / 255.0
X_test = X_test / 255.0

"""# **Augmentation Pipeline**"""

datagen = ImageDataGenerator(
    rotation_range=20,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

datagen.fit(X_train)

"""# **VGG19**"""

from tensorflow.keras import layers, models, optimizers

def build_vgg19(input_shape):
    model = models.Sequential()

    # Block 1
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 2
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 3
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 4
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 5
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Fully connected layers
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4, activation='softmax'))

    return model

# Build and compile the VGG19 model
input_shape = (img_size, img_size, 3)
vgg19_model = build_vgg19(input_shape)
vgg19_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
VGG19 = vgg19_model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=(X_test, y_test))

y_pred = vgg19_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)

label_mapping = {'Glioma': 0, 'Meningioma': 1, 'No Tumor': 2, 'Pituitary': 3}
class_names = {v: k for k, v in label_mapping.items()}

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names.values(), yticklabels=class_names.values())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of VGG19 Model')
plt.show()
print(classification_report(y_test, y_pred_classes, target_names=list(class_names.values())))

"""# **VGG16**"""

from tensorflow.keras import layers, models, optimizers

def build_vgg16(input_shape):
    model = models.Sequential()

    # Block 1
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 2
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 3
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 4
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 5
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))

    # Fully connected layers
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4, activation='softmax'))

    return model

# Build and compile the VGG16 model
input_shape = (img_size, img_size, 3)
vgg16_model = build_vgg16(input_shape)
vgg16_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
VGG16 = vgg16_model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=(X_test, y_test))

y_pred = vgg16_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)

label_mapping = {'Glioma': 0, 'Meningioma': 1, 'No Tumor': 2, 'Pituitary': 3}
class_names = {v: k for k, v in label_mapping.items()}

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names.values(), yticklabels=class_names.values())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of VGG16 Model')
plt.show()
print(classification_report(y_test, y_pred_classes, target_names=list(class_names.values())))

"""# **GoogleNet**"""

import tensorflow as tf
from tensorflow.keras import layers, models, Input

# Inception Module

def inception_module(x, filters):
    # 1x1 conv
    path1 = layers.Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)

    # 3x3 conv
    path2 = layers.Conv2D(filters[1], (1, 1), padding='same', activation='relu')(x)
    path2 = layers.Conv2D(filters[2], (3, 3), padding='same', activation='relu')(path2)

    # 5x5 conv
    path3 = layers.Conv2D(filters[3], (1, 1), padding='same', activation='relu')(x)
    path3 = layers.Conv2D(filters[4], (5, 5), padding='same', activation='relu')(path3)

    # 3x3 max pooling
    path4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    path4 = layers.Conv2D(filters[5], (1, 1), padding='same', activation='relu')(path4)

    return layers.concatenate([path1, path2, path3, path4], axis=-1)

def googlenet(input_shape):
    inputs = Input(shape=input_shape)

    # First convolutional layer with 7x7 filters
    x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)
    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    # Second convolutional layer with 1x1 filter, followed by 3x3 filter
    x = layers.Conv2D(64, (1, 1), padding='same', activation='relu')(x)
    x = layers.Conv2D(192, (3, 3), padding='same', activation='relu')(x)
    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    # Inception module 1
    x = inception_module(x, [64, 96, 128, 16, 32, 32])

    # Inception module 2
    x = inception_module(x, [128, 128, 192, 32, 96, 64])
    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    # Inception module 3
    x = inception_module(x, [192, 96, 208, 16, 48, 64])

    # Global average pooling
    x = layers.GlobalAveragePooling2D()(x)

    # Dropout layer
    x = layers.Dropout(0.5)(x)

    # Output layer
    outputs = layers.Dense(4, activation='softmax')(x)

    model = models.Model(inputs, outputs)
    return model

# Build and compile the GoogleNet model
input_shape = (img_size, img_size, 3)
googlenet_model = googlenet(input_shape)
googlenet_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
Inception = googlenet_model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=(X_test, y_test))

y_pred = googlenet_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)

label_mapping = {'Glioma': 0, 'Meningioma': 1, 'No Tumor': 2, 'Pituitary': 3}
class_names = {v: k for k, v in label_mapping.items()}

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names.values(), yticklabels=class_names.values())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of GoogleNet Model')
plt.show()
print(classification_report(y_test, y_pred_classes, target_names=list(class_names.values())))

"""# **ResNet50**"""

import tensorflow as tf
from tensorflow.keras import layers, models, Input

def identity_block(x, filters, kernel_size):
    f1, f2, f3 = filters

    x_shortcut = x

    x = layers.Conv2D(f1, (1, 1), strides=(1, 1), padding='valid')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(f2, kernel_size, strides=(1, 1), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(f3, (1, 1), strides=(1, 1), padding='valid')(x)
    x = layers.BatchNormalization()(x)

    x = layers.Add()([x, x_shortcut])
    x = layers.ReLU()(x)

    return x

def convolutional_block(x, filters, kernel_size, strides=(2, 2)):
    f1, f2, f3 = filters

    x_shortcut = x

    x = layers.Conv2D(f1, (1, 1), strides=strides, padding='valid')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(f2, kernel_size, strides=(1, 1), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(f3, (1, 1), strides=(1, 1), padding='valid')(x)
    x = layers.BatchNormalization()(x)

    x_shortcut = layers.Conv2D(f3, (1, 1), strides=strides, padding='valid')(x_shortcut)
    x_shortcut = layers.BatchNormalization()(x_shortcut)

    x = layers.Add()([x, x_shortcut])
    x = layers.ReLU()(x)

    return x

def resnet50(input_shape):
    inputs = Input(shape=input_shape)

    x = layers.ZeroPadding2D((3, 3))(inputs)
    x = layers.Conv2D(64, (7, 7), strides=(2, 2))(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)

    x = convolutional_block(x, filters=[64, 64, 256], kernel_size=(3, 3), strides=(1, 1))
    x = identity_block(x, filters=[64, 64, 256], kernel_size=(3, 3))
    x = identity_block(x, filters=[64, 64, 256], kernel_size=(3, 3))

    x = convolutional_block(x, filters=[128, 128, 512], kernel_size=(3, 3), strides=(2, 2))
    x = identity_block(x, filters=[128, 128, 512], kernel_size=(3, 3))
    x = identity_block(x, filters=[128, 128, 512], kernel_size=(3, 3))
    x = identity_block(x, filters=[128, 128, 512], kernel_size=(3, 3))

    x = convolutional_block(x, filters=[256, 256, 1024], kernel_size=(3, 3), strides=(2, 2))
    x = identity_block(x, filters=[256, 256, 1024], kernel_size=(3, 3))
    x = identity_block(x, filters=[256, 256, 1024], kernel_size=(3, 3))
    x = identity_block(x, filters=[256, 256, 1024], kernel_size=(3, 3))
    x = identity_block(x, filters=[256, 256, 1024], kernel_size=(3, 3))
    x = identity_block(x, filters=[256, 256, 1024], kernel_size=(3, 3))

    x = convolutional_block(x, filters=[512, 512, 2048], kernel_size=(3, 3), strides=(2, 2))
    x = identity_block(x, filters=[512, 512, 2048], kernel_size=(3, 3))
    x = identity_block(x, filters=[512, 512, 2048], kernel_size=(3, 3))

    x = layers.AveragePooling2D((2, 2), padding='same')(x)

    x = layers.Flatten()(x)
    x = layers.Dense(4, activation='softmax')(x)

    model = models.Model(inputs, x)
    return model

input_shape = (img_size, img_size, 3)
resnet_model = resnet50(input_shape)
resnet_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
ResNet50_Hist = resnet_model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=(X_test, y_test))

y_pred = resnet_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)

label_mapping = {'Glioma': 0, 'Meningioma': 1, 'No Tumor': 2, 'Pituitary': 3}
class_names = {v: k for k, v in label_mapping.items()}

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names.values(), yticklabels=class_names.values())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of ResNet50 Model')
plt.show()
print(classification_report(y_test, y_pred_classes, target_names=list(class_names.values())))

"""# **DenseNet121**"""

import tensorflow as tf
from tensorflow.keras import layers, models, Input

def dense_block(x, num_layers, growth_rate):
    for _ in range(num_layers):
        x = conv_block(x, growth_rate)
    return x

def conv_block(x, growth_rate):
    x1 = layers.BatchNormalization()(x)
    x1 = layers.ReLU()(x1)
    x1 = layers.Conv2D(4 * growth_rate, (1, 1), padding='same', use_bias=False)(x1)
    x1 = layers.BatchNormalization()(x1)
    x1 = layers.ReLU()(x1)
    x1 = layers.Conv2D(growth_rate, (3, 3), padding='same', use_bias=False)(x1)
    x = layers.Concatenate()([x, x1])
    return x

def transition_block(x, reduction):
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), (1, 1), padding='same', use_bias=False)(x)
    x = layers.AvgPool2D((2, 2), strides=(2, 2))(x)
    return x

def DenseNet121(input_shape):
    inputs = Input(shape=input_shape)

    # Initial Convolution and Pooling
    x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='same', use_bias=False)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    # Dense Block 1
    x = dense_block(x, 6, 32)
    x = transition_block(x, 0.5)

    # Dense Block 2
    x = dense_block(x, 12, 32)
    x = transition_block(x, 0.5)

    # Dense Block 3
    x = dense_block(x, 24, 32)
    x = transition_block(x, 0.5)

    # Dense Block 4
    x = dense_block(x, 16, 32)

    # Classification Layer
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.GlobalAvgPool2D()(x)
    x = layers.Dense(4, activation='softmax')(x)

    model = models.Model(inputs, x)
    return model

input_shape = (img_size, img_size, 3)
densenet_model = DenseNet121(input_shape)
densenet_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
DenseNet121_Hist = densenet_model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=50, validation_data=(X_test, y_test))

y_pred = densenet_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)

label_mapping = {'Glioma': 0, 'Meningioma': 1, 'No Tumor': 2, 'Pituitary': 3}
class_names = {v: k for k, v in label_mapping.items()}

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names.values(), yticklabels=class_names.values())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of DenseNet121 Model')
plt.show()
print(classification_report(y_test, y_pred_classes, target_names=list(class_names.values())))

"""# **Curves**"""

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(VGG19.history['accuracy'], label='VGG19')
plt.plot(VGG16.history['accuracy'], label='VGG16')
plt.plot(Inception.history['accuracy'], label='GoogleNet')
plt.plot(ResNet50_Hist.history['accuracy'], label='ResNet50')
plt.plot(DenseNet121_Hist.history['accuracy'], label='DenseNet121')
plt.legend()
plt.title('Training Accuracy')

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(VGG19.history['val_accuracy'], label='VGG19')
plt.plot(VGG16.history['val_accuracy'], label='VGG16')
plt.plot(Inception.history['val_accuracy'], label='GoogleNet')
plt.plot(ResNet50_Hist.history['val_accuracy'], label='ResNet50')
plt.plot(DenseNet121_Hist.history['val_accuracy'], label='DenseNet121')
plt.legend()
plt.title('Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(VGG19.history['loss'], label='VGG19')
plt.plot(VGG16.history['loss'], label='VGG16')
plt.plot(Inception.history['loss'], label='GoogleNet')
plt.plot(ResNet50_Hist.history['loss'], label='ResNet50')
plt.plot(DenseNet121_Hist.history['loss'], label='DenseNet121')
plt.legend()
plt.title('Training Loss')

plt.subplot(1, 2, 2)
plt.plot(VGG19.history['val_loss'], label='VGG19')
plt.plot(VGG16.history['val_loss'], label='VGG16')
plt.plot(Inception.history['val_loss'], label='GoogleNet')
plt.plot(ResNet50_Hist.history['val_loss'], label='ResNet50')
plt.plot(DenseNet121_Hist.history['val_loss'], label='DenseNet121')
plt.legend()
plt.title('Validation Loss')